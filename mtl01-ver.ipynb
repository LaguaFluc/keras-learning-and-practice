{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import required libraries\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nimport tensorflow as tf\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dense , LSTM, Dropout\nfrom tensorflow.keras.models import Sequential, load_model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport math\n# import xgboost\nimport time\nfrom tqdm import tqdm\n\n# Setting seed for reproducibility\nimport random\nnp.random.seed(1234)\nPYTHONHASHSEED = 1234\ntf.random.set_seed(1234)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T06:01:55.070762Z","iopub.execute_input":"2021-12-07T06:01:55.071739Z","iopub.status.idle":"2021-12-07T06:02:02.232758Z","shell.execute_reply.started":"2021-12-07T06:01:55.071632Z","shell.execute_reply":"2021-12-07T06:02:02.231824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['unit_number','time_in_cycles','setting_1','setting_2',\n           'TRA','T2','T24','T30','T50','P2','P15','P30','Nf',\n           'Nc','epr','Ps30','phi','NRf','NRc','BPR','farB',\n           'htBleed','Nf_dmd','PCNfR_dmd','W31','W32' \n          ]\n# '../input/phmdataset'\ntrain_orig = pd.read_csv('../input/phmdataset/train_orig.csv', header=None)\ntest_x_orig = pd.read_csv('../input/phmdataset/test_x_orig.csv', header=None)\ntest_y_orig = pd.read_csv('../input/phmdataset/test_y_orig.csv', header=None)\n\ntrain_orig.columns = columns\ntest_x_orig.columns = columns","metadata":{"execution":{"iopub.status.busy":"2021-12-07T06:02:04.499038Z","iopub.execute_input":"2021-12-07T06:02:04.499329Z","iopub.status.idle":"2021-12-07T06:02:04.739179Z","shell.execute_reply.started":"2021-12-07T06:02:04.499296Z","shell.execute_reply":"2021-12-07T06:02:04.738234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import pipeline\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# Combine the X values to normalize them, \nall_data_orig = pd.concat([train_orig, test_x_orig])\n# all_data = all_data[feature_cols]\n# all_data[feature_cols] = normalize(all_data[feature_cols].values)\n\nmmscaler = MinMaxScaler(feature_range=(-1, 1))\nall_data = all_data_orig.copy()\nscaler=pipeline.Pipeline(steps=[\n     ('minmax', MinMaxScaler(feature_range=(-1, 1))),\n     ('remove_constant', VarianceThreshold())\n])\n\nfeature_cols = columns[2:]\nall_data = all_data_orig.copy()\nall_data = np.concatenate(\n    [\n        all_data.iloc[:, :2], \n        scaler.fit_transform(all_data.iloc[:,2:])\n    ], \n    axis=1)\n\n\n# then split them back out\ntrain = all_data[0:train_orig.shape[0], :]\ntest = all_data[train_orig.shape[0]:, :]\n\n# Make engine numbers and days zero-indexed, for everybody's sanity\ntrain[:, 0:2] -= 1\ntest[:, 0:2] -= 1","metadata":{"execution":{"iopub.status.busy":"2021-12-07T06:02:06.23988Z","iopub.execute_input":"2021-12-07T06:02:06.240208Z","iopub.status.idle":"2021-12-07T06:02:06.318563Z","shell.execute_reply.started":"2021-12-07T06:02:06.240175Z","shell.execute_reply":"2021-12-07T06:02:06.317332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ndef get_labels(x, max_val, bins=0.05):\n#     print(x, max_val)\n#     max_val = max(x)\n    \n    n = 1 / bins + 1\n    interval = max_val * bins\n    if 0 <= x <= interval:\n        return 0 if x < interval * 0.5 else 1\n    for i in range(1, 21):\n        if interval * i < x <= interval * (i + 1):\n            return i if x < interval * i + 0.5 * interval else i + 1\n    return 20\n    \n\ndef prepare_data(engine, time, x, window, mask_value, is_test=False):\n    n_engines = 100\n    out_y_clf = []\n    out_y_reg = []\n    out_x = []\n    d = x.shape[1]\n    \n    for i in range(n_engines):\n        max_run_time = int(np.max(time[engine==i])) + 1\n        if not is_test:\n            start = 0\n        else:\n            start = max_run_time - 1\n        \n        this_x = []\n        this_y = []\n        \n        for j in range(start, max_run_time):\n            engine_x = x[engine==i]\n            if not is_test:\n                # 不用再加上一个1了\n                labels = get_labels(max_run_time - j, max_run_time)\n                this_y.append(np.array([labels]))\n                out_y_reg.append(np.array((max_run_time - j,), ndmin=2))\n            # x_temp = np.zeros((1, window, d))\n            x_temp = np.zeros((window, d))\n            x_temp += mask_value\n            \n            # x_temp[:, max(0, window - j - 1):window, :] = engine_x[max(0, j - window + 1):j + 1, :]\n            x_temp[max(0, window - j - 1):window, :] = engine_x[max(0, j - window + 1):j + 1, :]\n            this_x.append(x_temp)\n        if not is_test:\n            out_y_clf.append(this_y)\n        out_x.append(this_x)\n        \n    out_x = np.concatenate(out_x)\n    if not is_test:\n        out_y_clf = np.concatenate(out_y_clf)\n        out_y_clf = to_categorical(out_y_clf, num_classes=21, dtype='int16')\n        out_y_reg = np.concatenate(out_y_reg)\n    return out_x, (out_y_clf, out_y_reg)\n\nmask_value = -99\ntrain_x, train_y = prepare_data(\n    engine=train[:, 0], time=train[:, 1],\n    x=train[:, 2:],\n    window=50,\n    is_test=False,\n    mask_value=mask_value\n)\n\ntest_x, _ = prepare_data(\n    engine=test[:, 0], time=test[:, 1],\n    x=test[:, 2:],\n    window=50,\n    is_test=True,\n    mask_value=mask_value  \n)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T06:02:08.735626Z","iopub.execute_input":"2021-12-07T06:02:08.735921Z","iopub.status.idle":"2021-12-07T06:02:10.806584Z","shell.execute_reply.started":"2021-12-07T06:02:08.735887Z","shell.execute_reply":"2021-12-07T06:02:10.805604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y_clf, train_y_reg = train_y\ntrain_x.shape, train_y_clf.shape, train_y_reg.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T06:02:13.193286Z","iopub.execute_input":"2021-12-07T06:02:13.193774Z","iopub.status.idle":"2021-12-07T06:02:13.200846Z","shell.execute_reply.started":"2021-12-07T06:02:13.193726Z","shell.execute_reply":"2021-12-07T06:02:13.200293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, LSTM, Masking\nfrom tensorflow.keras.layers import Layer, concatenate\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\nfrom tensorflow.keras.metrics import MeanAbsoluteError, Accuracy\n\ninputs = tf.keras.Input(shape=(train_x.shape[1], train_x.shape[2]))\nx = Masking(mask_value=50)(inputs)\nx = LSTM(50)(x)\n\nout1 = Dense(50, activation='relu')(x)\nout1 = Dense(21, activation='softmax', name='output_1')(out1)\n\nout2 = Dense(50, activation='relu')(x)\nout2 = Dense(1, activation='relu', name='output_2')(out2)\n\nmodel = tf.keras.Model(inputs=[inputs], outputs=[out1, out2])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.RMSprop(0.003),\n    loss={\n        'output_1': CategoricalCrossentropy(),\n        'output_2': MeanSquaredError()\n    },\n    loss_weights={\n        'output_1': 0.95,\n        'output_2': 0.05\n    },\n    metrics={\n        'output_1': Accuracy(),\n        'output_2': MeanAbsoluteError()\n    }\n)\n\n\ncheckpoint_filepath = 'MTL-1130-0.001-{epoch:02d}-{val_loss:.2f}.hdf5'\nh_6_m5 = model.fit(\n    train_x, train_y, \n    epochs=400, batch_size=64, \n    validation_split=0.02,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n#         tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T06:02:32.249891Z","iopub.execute_input":"2021-12-07T06:02:32.25041Z","iopub.status.idle":"2021-12-07T08:02:05.729593Z","shell.execute_reply.started":"2021-12-07T06:02:32.250341Z","shell.execute_reply":"2021-12-07T08:02:05.729005Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# h_6_m5\n# h_6_m5\nkeys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.30.RMSprop(0.005),loss_weight:0.95, 0.05, epochs=400,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_6_m5.history[keys[idx]][:250])\n    axs[i][j].set_title(keys[idx])\naxs[3][0].hlines(0.5, xmin=0, xmax=len(h_6_m5.history[keys[idx]]), color='red')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:50:21.300329Z","iopub.execute_input":"2021-12-07T08:50:21.30123Z","iopub.status.idle":"2021-12-07T08:50:22.559814Z","shell.execute_reply.started":"2021-12-07T08:50:21.301186Z","shell.execute_reply":"2021-12-07T08:50:22.558897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(train_x)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:12:08.279969Z","iopub.execute_input":"2021-12-07T08:12:08.280327Z","iopub.status.idle":"2021-12-07T08:12:19.785237Z","shell.execute_reply.started":"2021-12-07T08:12:08.28029Z","shell.execute_reply":"2021-12-07T08:12:19.784327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e = np.abs(y_pred[1] - train_y[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:16:58.962258Z","iopub.execute_input":"2021-12-07T08:16:58.962804Z","iopub.status.idle":"2021-12-07T08:16:58.967655Z","shell.execute_reply.started":"2021-12-07T08:16:58.962754Z","shell.execute_reply":"2021-12-07T08:16:58.967027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = y_pred[1] - train_y[1]\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\naxs[0].plot(error)\naxs[0].set_title('error, error=y_pred_clf - y_true_clf')\n\naxs[1].plot(error[:18000])\naxs[1].set_title('error[:18000], error=y_pred_clf - y_true_clf')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:56:16.602007Z","iopub.execute_input":"2021-12-07T08:56:16.602307Z","iopub.status.idle":"2021-12-07T08:56:17.020772Z","shell.execute_reply.started":"2021-12-07T08:56:16.602272Z","shell.execute_reply":"2021-12-07T08:56:17.01984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(error[error>10]) / len(error)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:19:58.77113Z","iopub.execute_input":"2021-12-07T08:19:58.771658Z","iopub.status.idle":"2021-12-07T08:19:58.778462Z","shell.execute_reply.started":"2021-12-07T08:19:58.771608Z","shell.execute_reply":"2021-12-07T08:19:58.777639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_clf, y_pred_clf = np.argmax(train_y[0], axis=1), np.argmax(y_pred[0], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:24:15.349903Z","iopub.execute_input":"2021-12-07T08:24:15.350698Z","iopub.status.idle":"2021-12-07T08:24:15.35641Z","shell.execute_reply.started":"2021-12-07T08:24:15.350661Z","shell.execute_reply":"2021-12-07T08:24:15.355787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(y_true_clf)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:27:13.938694Z","iopub.execute_input":"2021-12-07T08:27:13.939032Z","iopub.status.idle":"2021-12-07T08:27:13.945153Z","shell.execute_reply.started":"2021-12-07T08:27:13.938982Z","shell.execute_reply":"2021-12-07T08:27:13.944302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame([y_true_clf, y_pred_clf])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:24:54.50681Z","iopub.execute_input":"2021-12-07T08:24:54.50714Z","iopub.status.idle":"2021-12-07T08:24:55.408082Z","shell.execute_reply.started":"2021-12-07T08:24:54.507104Z","shell.execute_reply":"2021-12-07T08:24:55.407235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.hist(e[:18000], 100, density=True, facecolor='g', alpha=0.75)\nn, bins, patches = plt.hist(error[:15000], 100, density=True, facecolor='g', alpha=0.75)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T08:42:28.37762Z","iopub.execute_input":"2021-12-07T08:42:28.377952Z","iopub.status.idle":"2021-12-07T08:42:28.805722Z","shell.execute_reply.started":"2021-12-07T08:42:28.377906Z","shell.execute_reply":"2021-12-07T08:42:28.804765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(12, 4))\nn, bins, patches = axs[0].hist(error, 100, density=True, facecolor='g', alpha=0.75)\naxs[0].set_title('error')\n\nn, bins, patches = axs[1].hist(error[:18000], 100, density=True, facecolor='r', alpha=0.75)\naxs[1].set_title('error[:18000]')\n\nfig.suptitle('error = y_pred_clf - y_true_clf')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T09:10:05.803475Z","iopub.execute_input":"2021-12-07T09:10:05.803852Z","iopub.status.idle":"2021-12-07T09:10:06.629282Z","shell.execute_reply.started":"2021-12-07T09:10:05.803817Z","shell.execute_reply":"2021-12-07T09:10:06.628671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_orig.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T09:22:52.873778Z","iopub.execute_input":"2021-12-07T09:22:52.87408Z","iopub.status.idle":"2021-12-07T09:22:53.250526Z","shell.execute_reply.started":"2021-12-07T09:22:52.874049Z","shell.execute_reply":"2021-12-07T09:22:53.249661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_orig[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-07T09:37:59.579244Z","iopub.execute_input":"2021-12-07T09:37:59.579545Z","iopub.status.idle":"2021-12-07T09:37:59.588014Z","shell.execute_reply.started":"2021-12-07T09:37:59.579516Z","shell.execute_reply":"2021-12-07T09:37:59.587408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(x, max_val, bins=0.05):\n#     print(x, max_val)\n#     max_val = max(x)\n#     print(type(x))\n    \n    n = 1 / bins + 1\n    interval = max_val * bins\n#     print(x.values)\n    x = int(x.values)\n    if 0 <= x <= interval:\n        return 0 if x < interval * 0.5 else 1\n    for i in range(1, 21):\n        if interval * i < x <= interval * (i + 1):\n            return i if x < interval * i + 0.5 * interval else i + 1\n    return 20","metadata":{"execution":{"iopub.status.busy":"2021-12-07T09:46:51.926046Z","iopub.execute_input":"2021-12-07T09:46:51.926355Z","iopub.status.idle":"2021-12-07T09:46:51.933191Z","shell.execute_reply.started":"2021-12-07T09:46:51.926314Z","shell.execute_reply":"2021-12-07T09:46:51.932426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = pd.Series([1, 2, 3])\ndef func(x, const):\n    return x + const\n# a.apply(get_labels, args=(145,))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T09:47:54.429859Z","iopub.execute_input":"2021-12-07T09:47:54.430153Z","iopub.status.idle":"2021-12-07T09:47:54.435385Z","shell.execute_reply.started":"2021-12-07T09:47:54.430125Z","shell.execute_reply":"2021-12-07T09:47:54.434533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_reg.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T09:48:06.019783Z","iopub.execute_input":"2021-12-07T09:48:06.020058Z","iopub.status.idle":"2021-12-07T09:48:06.025956Z","shell.execute_reply.started":"2021-12-07T09:48:06.020029Z","shell.execute_reply":"2021-12-07T09:48:06.025111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_reg = test_y_orig.copy()\nmax_val = int(test_y_reg.max())\n\ntest_y_clf = test_y_reg.apply(get_labels, args=(max_val,), axis=1)\ntest_y_clf = to_categorical(test_y_clf, num_classes=21, dtype='int16')\ntest_y_clf = np.argmax(test_y_clf, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:06:10.239576Z","iopub.execute_input":"2021-12-07T10:06:10.24011Z","iopub.status.idle":"2021-12-07T10:06:10.250001Z","shell.execute_reply.started":"2021-12-07T10:06:10.240042Z","shell.execute_reply":"2021-12-07T10:06:10.249317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_pred = model.predict(test_x)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:03:22.865318Z","iopub.execute_input":"2021-12-07T10:03:22.865606Z","iopub.status.idle":"2021-12-07T10:03:22.976155Z","shell.execute_reply.started":"2021-12-07T10:03:22.865576Z","shell.execute_reply":"2021-12-07T10:03:22.975442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_pred_clf, test_y_pred_reg = test_y_pred\ntest_y_pred_clf = np.argmax(test_y_pred_clf, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:07:24.967042Z","iopub.execute_input":"2021-12-07T10:07:24.967466Z","iopub.status.idle":"2021-12-07T10:07:24.971822Z","shell.execute_reply.started":"2021-12-07T10:07:24.967436Z","shell.execute_reply":"2021-12-07T10:07:24.971138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_clf.shape, test_y_pred_clf.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:07:26.913771Z","iopub.execute_input":"2021-12-07T10:07:26.914178Z","iopub.status.idle":"2021-12-07T10:07:26.919862Z","shell.execute_reply.started":"2021-12-07T10:07:26.914132Z","shell.execute_reply":"2021-12-07T10:07:26.919076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame([test_y_clf, test_y_pred_clf])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:07:58.178859Z","iopub.execute_input":"2021-12-07T10:07:58.179272Z","iopub.status.idle":"2021-12-07T10:07:58.201701Z","shell.execute_reply.started":"2021-12-07T10:07:58.179234Z","shell.execute_reply":"2021-12-07T10:07:58.200837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_test = test_y_clf - test_y_pred_clf\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\naxs[0].plot(error_test)\naxs[0].set_title('the curve of error_test')\nn, bins, patches = axs[1].hist(error_test, 20)\naxs[1].set_title('the distribution or error_test')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:20:12.427651Z","iopub.execute_input":"2021-12-07T10:20:12.428016Z","iopub.status.idle":"2021-12-07T10:20:12.834171Z","shell.execute_reply.started":"2021-12-07T10:20:12.427976Z","shell.execute_reply":"2021-12-07T10:20:12.833329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(error_test[error_test > 4]) / len(error_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T10:15:38.399261Z","iopub.execute_input":"2021-12-07T10:15:38.399931Z","iopub.status.idle":"2021-12-07T10:15:38.408694Z","shell.execute_reply.started":"2021-12-07T10:15:38.399889Z","shell.execute_reply":"2021-12-07T10:15:38.407858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# h_6_m5\nkeys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.30.RMSprop(0.005),loss_weight:0.95, 0.05, epochs=400,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_6_m5.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T03:33:57.998264Z","iopub.execute_input":"2021-12-07T03:33:57.998867Z","iopub.status.idle":"2021-12-07T03:33:59.261363Z","shell.execute_reply.started":"2021-12-07T03:33:57.998822Z","shell.execute_reply":"2021-12-07T03:33:59.260717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# h_6_m5\nkeys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.30.RMSprop(0.005),loss_weight:0.95, 0.05, epochs=400,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_6_m5.history[keys[idx]][50:])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T03:35:39.775028Z","iopub.execute_input":"2021-12-07T03:35:39.775873Z","iopub.status.idle":"2021-12-07T03:35:40.95349Z","shell.execute_reply.started":"2021-12-07T03:35:39.775817Z","shell.execute_reply":"2021-12-07T03:35:40.952597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_6_m2 = model.fit(\n    train_x, train_y, \n    epochs=100, batch_size=64, \n    validation_split=0.02,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n#         tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T02:54:41.464766Z","iopub.execute_input":"2021-12-06T02:54:41.465687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# h_30_m\nkeys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.12.6.RMSprop(0.001),loss_weight:0.95, 0.05, epochs=200,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_30_m.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-12-06T02:52:44.556206Z","iopub.execute_input":"2021-12-06T02:52:44.556531Z","iopub.status.idle":"2021-12-06T02:52:45.907975Z","shell.execute_reply.started":"2021-12-06T02:52:44.556501Z","shell.execute_reply":"2021-12-06T02:52:45.907026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.30.RMSprop(0.001),loss_weight:0.95, 0.05, epochs=200,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_30_m.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T03:18:25.665123Z","iopub.execute_input":"2021-11-30T03:18:25.666108Z","iopub.status.idle":"2021-11-30T03:18:26.941211Z","shell.execute_reply.started":"2021-11-30T03:18:25.666062Z","shell.execute_reply":"2021-11-30T03:18:26.939827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_30_m = model.fit(\n    train_x, train_y, \n    epochs=50, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T03:22:28.13927Z","iopub.execute_input":"2021-11-30T03:22:28.139592Z","iopub.status.idle":"2021-11-30T03:39:50.285593Z","shell.execute_reply.started":"2021-11-30T03:22:28.139561Z","shell.execute_reply":"2021-11-30T03:39:50.284407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2021.11.29","metadata":{}},{"cell_type":"code","source":"h_29_n2\nkeys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.29.RMSprop(0.01),loss_weight:0.90, 0.10, epochs=200,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_29_n2.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:00:14.009822Z","iopub.execute_input":"2021-11-29T09:00:14.010183Z","iopub.status.idle":"2021-11-29T09:00:15.255439Z","shell.execute_reply.started":"2021-11-29T09:00:14.010149Z","shell.execute_reply":"2021-11-29T09:00:15.253666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_29_n2 = model.fit(\n    train_x, train_y, \n    epochs=50, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:01:00.457747Z","iopub.execute_input":"2021-11-29T09:01:00.458718Z","iopub.status.idle":"2021-11-29T09:17:18.858417Z","shell.execute_reply.started":"2021-11-29T09:01:00.458659Z","shell.execute_reply":"2021-11-29T09:17:18.857676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_29_n2 = model.fit(\n    train_x, train_y, \n    epochs=50, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:34:37.089711Z","iopub.execute_input":"2021-11-29T09:34:37.090224Z","iopub.status.idle":"2021-11-29T09:50:53.099988Z","shell.execute_reply.started":"2021-11-29T09:34:37.090172Z","shell.execute_reply":"2021-11-29T09:50:53.098889Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.29.RMSprop(0.01),loss_weight:0.90, 0.10, epochs=200(50)(50),batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_29_n2.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:53:04.421994Z","iopub.execute_input":"2021-11-29T09:53:04.422385Z","iopub.status.idle":"2021-11-29T09:53:05.861339Z","shell.execute_reply.started":"2021-11-29T09:53:04.422331Z","shell.execute_reply":"2021-11-29T09:53:05.860366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.29.RMSprop(0.03),loss_weight:0.95, 0.05, epochs=200(50),batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_29_n2.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:33:59.101899Z","iopub.execute_input":"2021-11-29T09:33:59.102731Z","iopub.status.idle":"2021-11-29T09:34:00.326109Z","shell.execute_reply.started":"2021-11-29T09:33:59.102694Z","shell.execute_reply":"2021-11-29T09:34:00.325433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.29.RMSprop(0.01),loss_weight:0.90, 0.10, epochs=200,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_29_n1.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:35:42.330845Z","iopub.execute_input":"2021-11-29T07:35:42.33122Z","iopub.status.idle":"2021-11-29T07:35:43.613523Z","shell.execute_reply.started":"2021-11-29T07:35:42.33118Z","shell.execute_reply":"2021-11-29T07:35:43.612586Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, LSTM, Masking\nfrom tensorflow.keras.layers import Layer, concatenate\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\nfrom tensorflow.keras.metrics import MeanAbsoluteError, Accuracy\n\ninputs = tf.keras.Input(shape=(train_x.shape[1], train_x.shape[2]))\nx = Masking(mask_value=50)(inputs)\nx = LSTM(50)(x)\n\nout1 = Dense(50, activation='relu')(x)\nout1 = Dense(21, activation='softmax', name='output_1')(out1)\n\nout2 = Dense(50, activation='relu')(x)\nout2 = Dense(1, activation='relu', name='output_2')(out2)\n\nmodel = tf.keras.Model(inputs=[inputs], outputs=[out1, out2])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.RMSprop(0.05),\n    loss={\n        'output_1': CategoricalCrossentropy(),\n        'output_2': MeanSquaredError()\n    },\n    loss_weights={\n        'output_1': 0.95,\n        'output_2': 0.05\n    },\n    metrics={\n        'output_1': Accuracy(),\n        'output_2': MeanAbsoluteError()\n    }\n)\n\n# tbCallBack = tf.keras.callbacks.TensorBoard(\n#     log_dir='./woca_logs',  # log 目录                         \n#     histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算            \n#     batch_size=32,     # 用多大量的数据计算直方图                         \n#     write_graph=True,  # 是否存储网络结构图                         \n#     write_grads=True,  # 是否可视化梯度直方图                         \n#     write_images=True,  # 是否可视化参数                         \n#     embeddings_freq=0,                         \n#     embeddings_layer_names=None,                         \n#     embeddings_metadata=None\n# )\n\ncheckpoint_filepath = 'MTL-{epoch:02d}-{val_loss:.2f}.hdf5'\nh_27_n1 = model.fit(\n    train_x, train_y, \n    epochs=200, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T02:03:33.57497Z","iopub.execute_input":"2021-11-29T02:03:33.575568Z","iopub.status.idle":"2021-11-29T03:00:45.543965Z","shell.execute_reply.started":"2021-11-29T02:03:33.57552Z","shell.execute_reply":"2021-11-29T03:00:45.542953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nkeys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.29.RMSprop(0.05),loss_weight:0.95, 0.05, epochs=200,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_27_n1.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T03:03:13.530488Z","iopub.execute_input":"2021-11-29T03:03:13.53078Z","iopub.status.idle":"2021-11-29T03:03:14.756206Z","shell.execute_reply.started":"2021-11-29T03:03:13.53075Z","shell.execute_reply":"2021-11-29T03:03:14.755143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = 'MTL-{epoch:02d}-{val_loss:.2f}.hdf5'\nh_27_n1 = model.fit(\n    train_x, train_y, \n    epochs=100, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T05:45:19.165968Z","iopub.execute_input":"2021-11-27T05:45:19.1664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = 'MTL-{epoch:02d}-{val_loss:.2f}.hdf5'\nh_26_n2 = model.fit(\n    train_x, train_y, \n    epochs=100, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='loss', min_delta=0, patience=20, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n        tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T07:58:02.856512Z","iopub.execute_input":"2021-11-26T07:58:02.856796Z","iopub.status.idle":"2021-11-26T08:28:25.866917Z","shell.execute_reply.started":"2021-11-26T07:58:02.856767Z","shell.execute_reply":"2021-11-26T08:28:25.865705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = ['loss', 'val_loss', \n        'output_1_loss', 'val_output_1_loss', \n        'output_2_loss', 'val_output_2_loss', \n        'output_1_accuracy',  'val_output_1_accuracy', \n        'output_2_mean_absolute_error', 'val_output_2_mean_absolute_error']\nfig, axs = plt.subplots(5, 2, figsize=(8, 12))\nfig.suptitle('2021.11.26.noon2.RMSprop(0.05),epochs=100,batch_size=64')\nfor idx in range(10):\n    i, j = idx // 2, idx % 2\n    axs[i][j].plot(h_26_n2.history[keys[idx]])\n    axs[i][j].set_title(keys[idx])","metadata":{"execution":{"iopub.status.busy":"2021-11-26T08:42:51.701521Z","iopub.execute_input":"2021-11-26T08:42:51.702128Z","iopub.status.idle":"2021-11-26T08:42:53.142549Z","shell.execute_reply.started":"2021-11-26T08:42:51.702072Z","shell.execute_reply":"2021-11-26T08:42:53.141622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# --------------------分割线--------------------","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, LSTM, Masking\nfrom tensorflow.keras.layers import Layer, concatenate\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\nfrom tensorflow.keras.metrics import MeanAbsoluteError, Accuracy\n\ninputs = tf.keras.Input(shape=(train_x.shape[1], train_x.shape[2]))\nx = Masking(mask_value=50)(inputs)\nx = LSTM(50)(x)\n\nout1 = Dense(50, activation='relu')(x)\nout1 = Dense(21, activation='softmax', name='output_1')(out1)\n\nout2 = Dense(50, activation='relu')(x)\nout2 = Dense(1, activation='relu', name='output_2')(out2)\n\nmodel = tf.keras.Model(inputs=[inputs], outputs=[out1, out2])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.RMSprop(0.001),\n    loss={\n        'output_1': CategoricalCrossentropy(),\n        'output_2': MeanSquaredError()\n    },\n    loss_weights={\n        'output_1': 0.5,\n        'output_2': 0.5\n    },\n    metrics={\n        'output_1': Accuracy(),\n        'output_2': MeanAbsoluteError()\n    }\n)\n\n\ncheckpoint_filepath = 'MTL-1126n3-{epoch:02d}-{val_loss:.2f}.hdf5'\nh_26_n2 = model.fit(\n    train_x, train_y, \n    epochs=300, batch_size=64, \n    validation_split=0.05,\n#     validation_data = (test_x, test_y),\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor='loss', min_delta=0, patience=50, verbose=0, mode='min'),\n        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath ,monitor=\"val_accuracy\", verbose=0,save_best_only=False),\n        tf.keras.callbacks.TerminateOnNaN(),\n#         tbCallBack\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T08:45:45.567796Z","iopub.execute_input":"2021-11-26T08:45:45.568098Z","iopub.status.idle":"2021-11-26T10:17:29.143796Z","shell.execute_reply.started":"2021-11-26T08:45:45.568065Z","shell.execute_reply":"2021-11-26T10:17:29.142063Z"},"trusted":true},"execution_count":null,"outputs":[]}]}